1. Przygotowanie kodu wczytującego i wizualizującego elementy zbioru danych. Obiektu typu Dataset który będzie opakowywał dostęp do danych powinien zwracać w oczekiwanym formacie (dwa obrazy plus jedna maska segmentacji) - Patryk
2. Zaimplementować bazową architekturę opisaną w artykule jako Flood Attribution Network korzystając z publicznie dostępnych implementacji Unetu w PyTorchu (np. tej: https://amaarora.github.io/posts/2020-09-13-unet.html, ale wiele innych jest dostępnych w sieci) - Paweł
3. Implementacja pętli treningowej i ewaluacyjnej w Pytorch Lightning. Ewaluacja na tym etapie opcjonalna - Patryk


	
Dalsze kroki:
Określić metryki jakie będą wykrozystywane do ewaluacji modelu  - jako minimum warto liczyć precyzję, kompletność (recall), Dice score (więcej info: https://www.kaggle.com/code/yassinealouini/all-the-segmentation-metrics). W bibliotece PytorchLigtning te metryki są zaimplementowane - i można je wykorzystać: https://lightning.ai/docs/torchmetrics/stable/classification/dice.html
Wygląda na relatywnie prostą w implementacji - przepuszczenie dwóch obrazów przez tę samą kopię Uneta (shared weights to oznacza), sklejenie wynikowych map i oparcie o nie klasyfikacji per-pixel 5 klas. Mogę wyjaśnić później szczegóły.
Przeprowadzić kilka eksperymentów - i zebrać wyniki. Przykładowo można sprawdzić:
Sprawdzenie różnych wariantów architektury modelu - np. łączenie map cech z obu obrazach na wcześniejszych etapach przetwarzania; wykorzystanie dwóch osobnych sieci do każdego z obrazów; wykorzystanie globalnego kontekstu (aby wszystkie obiekty na jednym obrazie spójnie klasyfikować jakos zalane/nie zalane).
Sprawdzenie różnych podejść do augmentacji danych (np, stworzenie kilka zestawów augmetnacji zlożonych z przekształceń geometrycznych i fotometrycznych o różnym natężeniu i sprawdzeniu ktory daje najlepsze efekty).
Eksperymentalny wybór funkcji straty (entropia krzyżowa, dice loss, focal loss, lovasz loss) i ew. liniowych kombinacji wybrnaych funkcji straty,
Opcjonalnie, o ile będzie czas, sprawdzenie innych pomysłów, które potencjalnie moga poprawić wyniki. Np,. przygotowani masek do semantycznej segmentacji z wykorzystaniem transformaty odleglości (distance transform) aby lepiej wykrywać krawędzie budynków i wąskie drogi.
